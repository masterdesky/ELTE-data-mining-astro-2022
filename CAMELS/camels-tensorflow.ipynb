{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14973bf4-6227-44be-b1c6-29b0a8d6aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as kl\n",
    "from tensorflow.keras import models as km\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import callbacks as kc\n",
    "from tensorflow.keras import optimizers as ko\n",
    "from tensorflow.keras import regularizers as kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da77fb00-e434-4df1-b372-deffc189c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if GPU is available for TensorFlow\n",
    "print(f\"GPU : {tf.config.list_physical_devices('GPU')}\")\n",
    "# Check TensorFlow version\n",
    "print(f\"TF version : {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ed5a25-dd27-4c61-a967-28df78e1bc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDIR = '/home/masterdesky/data/CAMELS/2D_maps/data/'\n",
    "FILE = os.listdir(DDIR)\n",
    "FILE = sorted([\n",
    "    f for f in FILE if ('.txt' not in f) & ('_CV_' not in f)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd28cf3-76a0-4cbc-ba0a-c39d729fe6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4ebeb-d520-4fec-9409-d1449e5b2112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf254fd-f6d0-4faa-be4e-1826bebb9ac4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load a selected datafile\n",
    "f = FILE[5]\n",
    "X = np.load(os.path.join(DDIR, f), allow_pickle=True)\n",
    "X = np.log10(X)\n",
    "\n",
    "# Load labels\n",
    "dataset = '_'.join(f.split('_')[2:-2])\n",
    "y = np.genfromtxt(os.path.join(DDIR, f\"params_{dataset}.txt\"))\n",
    "y = np.repeat(y, 15, axis=0)\n",
    "\n",
    "test_size = 0.33\n",
    "valid_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                          test_size=test_size, random_state=57)\n",
    "del(X)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train,\n",
    "                          test_size=valid_size/(1-test_size), random_state=57)\n",
    "\n",
    "print('Train :', X_train.shape)\n",
    "print('Valid :', X_valid.shape)\n",
    "print('Test :', X_test.shape)\n",
    "\n",
    "#\n",
    "# TENSORFLOW PURGATORY IN EARLY 2022\n",
    "#\n",
    "# Wrap data in Dataset objects\n",
    "train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "valid_data = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "del(X_train); del(y_train)\n",
    "del(X_valid); del(y_valid)\n",
    "\n",
    "# The batch size must now be set on the Dataset objects\n",
    "batch_size = 128\n",
    "train_data = train_data.batch(batch_size)\n",
    "valid_data = valid_data.batch(batch_size)\n",
    "\n",
    "# Disable AUTO sharding policy\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = \\\n",
    "                        tf.data.experimental.AutoShardPolicy.OFF\n",
    "train_data = train_data.with_options(options)\n",
    "valid_data = valid_data.with_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a1fab9-2099-4168-a19d-8e7fae599c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiCNN:\n",
    "    '''\n",
    "    Creates a CNN model for regression and classification problems with\n",
    "    multiple types of variables as their outputs. The model supports\n",
    "    square shaped images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    imsize : \n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 imsize, n_channels,\n",
    "                 num_filters, kernelsize, padding, stride, kreg,\n",
    "                 activation):\n",
    "        self.imsize = imsize\n",
    "        self.n_channels = n_channels\n",
    "        self.num_filters = num_filters\n",
    "        self.kernelsize = kernelsize\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        self.kreg = kreg\n",
    "        self.activation = activation\n",
    "\n",
    "        self.inputs = kl.Input(shape=(imsize, imsize, n_channels))\n",
    "        self.branches = []\n",
    "        \n",
    "    def __cnn__(self, inputs):\n",
    "        #\n",
    "        # Convolutional block 1.\n",
    "        # 3x3CONVx32 -> 3x3CONVx32 -> MAXPOOLx2\n",
    "        #\n",
    "        x = kl.Conv2D(filters=self.num_filters,\n",
    "                    kernel_size=(self.kernelsize, self.kernelsize),\n",
    "                    padding=self.padding,\n",
    "                    strides=(self.stride, self.stride),\n",
    "                    kernel_regularizer=kr.l2(self.kreg))(inputs)\n",
    "        x = kl.Activation(self.activation)(kl.BatchNormalization()(x))\n",
    "        \n",
    "        x = kl.Conv2D(filters=self.num_filters,\n",
    "                    kernel_size=(self.kernelsize, self.kernelsize),\n",
    "                    padding=self.padding,\n",
    "                    strides=(self.stride, self.stride),\n",
    "                    kernel_regularizer=kr.l2(self.kreg))(x)\n",
    "        x = kl.Activation(self.activation)(kl.BatchNormalization()(x))\n",
    "        \n",
    "        x = kl.MaxPooling2D(strides=(2, 2))(x)\n",
    "\n",
    "\n",
    "        #\n",
    "        # Convolutional block 2.\n",
    "        # 3x3CONVx64 -> 3x3CONVx64 -> MAXPOOLx2\n",
    "        #\n",
    "        x = kl.Conv2D(filters=2*self.num_filters,\n",
    "                    kernel_size=(self.kernelsize, self.kernelsize),\n",
    "                    padding=self.padding,\n",
    "                    strides=(self.stride, self.stride),\n",
    "                    kernel_regularizer=kr.l2(self.kreg))(x)\n",
    "        x = kl.Activation(self.activation)(kl.BatchNormalization()(x))\n",
    "\n",
    "        x = kl.Conv2D(filters=2*self.num_filters,\n",
    "                    kernel_size=(self.kernelsize, self.kernelsize),\n",
    "                    padding=self.padding,\n",
    "                    strides=(self.stride, self.stride),\n",
    "                    kernel_regularizer=kr.l2(self.kreg))(x)\n",
    "        x = kl.Activation(self.activation)(kl.BatchNormalization()(x))\n",
    "        \n",
    "        x = kl.MaxPooling2D(strides=(2, 2))(x)\n",
    "\n",
    "\n",
    "        #\n",
    "        # Convolutional block 3.\n",
    "        # 3x3CONVx128 -> 1x1CONVx64 -> 3x3CONVx128 -> MAXPOOLx2\n",
    "        #\n",
    "        x = kl.Conv2D(filters=4*self.num_filters,\n",
    "                    kernel_size=(self.kernelsize, self.kernelsize),\n",
    "                    padding=self.padding,\n",
    "                    strides=(self.stride, self.stride),\n",
    "                    kernel_regularizer=kr.l2(self.kreg))(x)\n",
    "        x = kl.Activation(self.activation)(kl.BatchNormalization()(x))\n",
    "\n",
    "        x = kl.Conv2D(filters=2*self.num_filters,\n",
    "                    kernel_size=(1, 1),\n",
    "                    padding=self.padding,\n",
    "                    kernel_regularizer=kr.l2(self.kreg))(x)\n",
    "        x = kl.Activation(self.activation)(kl.BatchNormalization()(x))\n",
    "\n",
    "        x = kl.Conv2D(filters=4*self.num_filters,\n",
    "                    kernel_size=(self.kernelsize, self.kernelsize),\n",
    "                    padding=self.padding,\n",
    "                    strides=(self.stride, self.stride),\n",
    "                    kernel_regularizer=kr.l2(self.kreg))(x)\n",
    "        x = kl.Activation(self.activation)(kl.BatchNormalization()(x))\n",
    "\n",
    "        x = kl.MaxPooling2D(strides=(2, 2))(x)\n",
    "\n",
    "\n",
    "        #\n",
    "        # Convolutional block 4.\n",
    "        # 3x3CONVx256 -> 1x1CONVx128 -> 3x3CONVx256 -> MAXPOOLx2\n",
    "        #\n",
    "        x = kl.Conv2D(filters=8*self.num_filters,\n",
    "                    kernel_size=(self.kernelsize, self.kernelsize),\n",
    "                    padding=self.padding,\n",
    "                    strides=(self.stride, self.stride),\n",
    "                    kernel_regularizer=kr.l2(self.kreg))(x)\n",
    "        x = kl.Activation(self.activation)(kl.BatchNormalization()(x))\n",
    "\n",
    "        x = kl.Conv2D(filters=4*self.num_filters,\n",
    "                    kernel_size=(1, 1),\n",
    "                    padding=self.padding,\n",
    "                    kernel_regularizer=kr.l2(self.kreg))(x)\n",
    "        x = kl.Activation(self.activation)(kl.BatchNormalization()(x))\n",
    "\n",
    "        x = kl.Conv2D(filters=8*self.num_filters,\n",
    "                    kernel_size=(self.kernelsize, self.kernelsize),\n",
    "                    padding=self.padding,\n",
    "                    strides=(self.stride, self.stride),\n",
    "                    kernel_regularizer=kr.l2(self.kreg))(x)\n",
    "        x = kl.Activation(self.activation)(kl.BatchNormalization()(x))\n",
    "\n",
    "        x = kl.MaxPooling2D(strides=(2, 2))(x)\n",
    "\n",
    "\n",
    "        #\n",
    "        # Convolutional block 5.\n",
    "        # 3x3CONVx512 -> 1x1CONVx256 -> 3x3CONVx512 -> AVGPOOL\n",
    "        #\n",
    "        x = kl.Conv2D(filters=16*self.num_filters,\n",
    "                      kernel_size=(self.kernelsize, self.kernelsize),\n",
    "                      padding=self.padding,\n",
    "                      strides=(self.stride, self.stride),\n",
    "                      kernel_regularizer=kr.l2(self.kreg))(x)\n",
    "        x = kl.Activation(self.activation)(kl.BatchNormalization()(x))\n",
    "\n",
    "        x = kl.Conv2D(filters=8*self.num_filters,\n",
    "                      kernel_size=(1, 1),\n",
    "                      padding=self.padding,\n",
    "                      kernel_regularizer=kr.l2(self.kreg))(x)\n",
    "        x = kl.Activation(self.activation)(kl.BatchNormalization()(x))\n",
    "\n",
    "        x = kl.Conv2D(filters=16*self.num_filters,\n",
    "                      kernel_size=(self.kernelsize, self.kernelsize),\n",
    "                      padding=self.padding,\n",
    "                      strides=(self.stride, self.stride),\n",
    "                      kernel_regularizer=kr.l2(self.kreg))(x)\n",
    "        x = kl.Activation(self.activation)(kl.BatchNormalization()(x))\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def add_branch(self,\n",
    "                   n_target, branch_name):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_target : int\n",
    "            Number of target values on this branch. Set `n_target = 1`\n",
    "            for regression problems, while `n_targets > 1` for\n",
    "            classification.\n",
    "        \n",
    "        branch_name : str\n",
    "            Arbitrary name given to the branch.\n",
    "        '''\n",
    "        assert branch_name is not None, \"Every branch should have a name!\"\n",
    "        ## CNN\n",
    "        x = self.__cnn__(self.inputs)\n",
    "        # Branch-specific parts\n",
    "        x = kl.GlobalAveragePooling2D()(x)\n",
    "        if n_target == 1: activation = None\n",
    "        else: activation = 'softmax'\n",
    "        x = kl.Dense(units=n_target, activation=activation,\n",
    "                     name = f\"{branch_name}\")(x)\n",
    "        \n",
    "        self.branches.append(x);\n",
    "\n",
    "    def get_model(self):\n",
    "        assert len(self.branches) > 0, \"No target branches added yet!\"\n",
    "        return km.Model(inputs=self.inputs, outputs=self.branches,\n",
    "                        name=\"multicnn_net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093327d8-f713-4dfb-ba9b-e7b9e78eed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = '0'\n",
    "GPU = [f\"GPU:{i}\" for i in gpu.split(',')]\n",
    "\n",
    "if len(gpu.split(',')) > 1:\n",
    "    strategy = tf.distribute.MirroredStrategy(GPU)\n",
    "else:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(GPU[0])\n",
    "\n",
    "with strategy.scope():\n",
    "    # Initialize the CNN template for all network branches\n",
    "    multi_cnn = MultiCNN(\n",
    "        imsize=256,\n",
    "        n_channels=1,\n",
    "        num_filters=32,\n",
    "        kernelsize=3,\n",
    "        padding='same',\n",
    "        stride=1,\n",
    "        kreg=5e-05,\n",
    "        activation='relu'\n",
    "    )\n",
    "    \n",
    "    # Add branches for all target value\n",
    "    multi_cnn.add_branch(n_target=1, branch_name=\"Omega_m\")\n",
    "    multi_cnn.add_branch(n_target=1, branch_name=\"sigma_8\")\n",
    "    multi_cnn.add_branch(n_target=1, branch_name=\"A_SN1\")\n",
    "    multi_cnn.add_branch(n_target=1, branch_name=\"A_AGN1\")\n",
    "    multi_cnn.add_branch(n_target=1, branch_name=\"A_SN2\")\n",
    "    multi_cnn.add_branch(n_target=1, branch_name=\"A_AGN2\")\n",
    "    \n",
    "    # Compile the model \n",
    "    model = multi_cnn.get_model()\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "    \n",
    "    # Create callback checkpoint\n",
    "    best_model = kc.ModelCheckpoint('best_model.hdf5',\n",
    "                                save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fa2acc-a0b0-46b6-abdc-d42b810e365d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30f994a-318b-425b-b4a8-d1c969c53223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "history = model.fit(train_data,#x=X_train, y=y_train,\n",
    "                    validation_data=valid_data,#(X_valid, y_valid),\n",
    "                    epochs=epochs,#batch_size=batch_size,\n",
    "                    callbacks=[best_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2574beed-fc45-4901-ac62-e9c6c185c0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
